{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition\n",
    "The goal of this work is to build a classifier for traffic sign recognition.\n",
    "The dataset consist of 50 000 images of traffic sign in different light condition\n",
    "Angle, resolution, luminosity.\n",
    "\n",
    "## Dataset\n",
    "* Total = 50000 \n",
    "* Class = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "In this section we will load the data. Note The data are in two format.\n",
    "* The extracted feature using Histogram Oriented Gradien in 3 Format HOG1, HOG2, HOG3\n",
    "* The actual image with the region of of interest in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2 as cv\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# function for reading the images\n",
    "# arguments: path to the traffic sign data\n",
    "# returns: list of images, list of corresponding labels \n",
    "\n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data \n",
    "    Arguments: path to the traffic sign data\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read traffic test sign\n",
    "def readTestTrafficSigns(rootpath):\n",
    "    \"\"\"Read traffic sign test data \n",
    "    Arguments: path to the test folder\n",
    "    Returns: list of images and list of the label\"\"\"\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    gtFile = open(rootpath+'/GT-final_test.test.csv')\n",
    "    gtReader = csv.reader(gtFile, delimiter=';')\n",
    "    \n",
    "    next(gtReader)\n",
    "    # loop over the row and low the image\n",
    "    for row in gtReader:\n",
    "        X_test.append(plt.imread(rootpath+'/'+row[0]))\n",
    "        y_test.append(row[6])\n",
    "    gtFile.close()\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readHogTrafficSigns(rootpath):\n",
    "    ''' Read HOG of traffic sign image\n",
    "    Arguments: path to the traffic sign hog data\n",
    "    Returns: list of HOG Array, list of corresponding labels'''\n",
    "    X_train = [] #list of hog\n",
    "    y_train = [] #list of labels\n",
    "    #loop over all 43 classes\n",
    "    for c in range(0,42):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        for file in glob.glob(prefix + '/*.txt'):\n",
    "            \n",
    "            X_train.append(np.loadtxt(file))\n",
    "            y_train.append(c)\n",
    "    return np.asarray(X_train), np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrafficHogTest(rootpath):\n",
    "    '''Reads traffic sign test data \n",
    "    Arguments: path to the traffic sign data\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    X_test = [] # images\n",
    "    y_test = [] # corresponding labels\n",
    "    \n",
    "    #Readinf the file with label and class \n",
    "    gtFile = open('./Database/BaseDeTest/Test_VeriteTerrain(GT).csv') # annotations file\n",
    "    # Read File \n",
    "    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "    next(gtReader) # skip header\n",
    "    for row in gtReader:\n",
    "        name = row[0].split('.')[0]+'.txt'\n",
    "        filename = rootpath+name\n",
    "        X_test.append(np.loadtxt(filename))\n",
    "        y_test.append(row[7])\n",
    "    gtFile.close()\n",
    "    return np.asarray(X_test), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, y_test = readTestTrafficSigns('./Database/BaseDeTest/Test_Images/Images')\n",
    "# Read train images features HOG\n",
    "X_train, y_train = readHogTrafficSigns('./Database/BaseDApprentissage/Training_HOG/HOG/HOG_02')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Data exploration\n",
    "The Data is already split into test and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38969, 1568)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = readTrafficHogTest('./Database/BaseDeTest/Test_HOG/HOG_02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "rfc=RandomForestClassifier(n_estimators=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 11.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9576405384006335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "#fit to the trainin data\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the test data with the pretrainned classifier\n",
    "y_predsvm = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8629453681710214\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.82      0.85      0.84       720\n",
      "           2       0.72      0.95      0.82       750\n",
      "           3       0.97      0.69      0.81       450\n",
      "           4       0.94      0.95      0.95       660\n",
      "           5       0.71      0.78      0.74       630\n",
      "           6       0.68      0.77      0.72       150\n",
      "           7       0.88      0.86      0.87       450\n",
      "           8       0.91      0.83      0.87       450\n",
      "           9       0.94      0.99      0.96       480\n",
      "          10       0.99      0.97      0.98       660\n",
      "          11       0.61      0.97      0.75       420\n",
      "          12       0.98      1.00      0.99       690\n",
      "          13       1.00      1.00      1.00       720\n",
      "          14       1.00      0.98      0.99       270\n",
      "          15       1.00      0.99      0.99       210\n",
      "          16       1.00      0.92      0.96       150\n",
      "          17       1.00      0.99      0.99       360\n",
      "          18       0.79      0.85      0.82       390\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.97      0.38      0.54        90\n",
      "          21       0.00      0.00      0.00        90\n",
      "          22       0.98      0.74      0.84       120\n",
      "          23       0.69      0.67      0.68       150\n",
      "          24       0.00      0.00      0.00        90\n",
      "          25       0.79      0.94      0.86       480\n",
      "          26       0.71      0.72      0.71       180\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.71      0.73      0.72       150\n",
      "          29       0.00      0.00      0.00        90\n",
      "          30       0.52      0.22      0.31       150\n",
      "          31       0.60      1.00      0.75       270\n",
      "          32       0.94      1.00      0.97        60\n",
      "          33       1.00      0.99      1.00       210\n",
      "          34       1.00      0.99      1.00       120\n",
      "          35       0.98      0.99      0.98       390\n",
      "          36       1.00      0.97      0.98       120\n",
      "          37       1.00      0.82      0.90        60\n",
      "          38       0.99      0.99      0.99       690\n",
      "          39       1.00      1.00      1.00        90\n",
      "          40       0.97      0.81      0.88        90\n",
      "          41       0.66      0.62      0.64        60\n",
      "          42       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.86     12630\n",
      "   macro avg       0.73      0.72      0.72     12630\n",
      "weighted avg       0.84      0.86      0.84     12630\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alessandra OSIAS\\.conda\\envs\\stopsign\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_predsvm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[  0  41   4 ...   0   0   0]\n",
      " [  0 614  94 ...   0   0   0]\n",
      " [  0   5 715 ...   0   0   0]\n",
      " ...\n",
      " [  0  10   0 ...  73   0   0]\n",
      " [  0   0   2 ...   0  37   0]\n",
      " [  0   0   5 ...   2  19   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_predsvm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
